{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "470a1ec8-32b7-4e70-8d07-76f878527b7d",
   "metadata": {},
   "source": [
    "# Milestone 1 Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4727891d-4be6-4c58-8db2-65c6b9500834",
   "metadata": {},
   "source": [
    "#### Authors: Julien Gordon, Adam Morphy, Mukund Iyer, Shiva Shankar Jena"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46fba66e-17cd-4249-b1bd-a285f634db86",
   "metadata": {},
   "source": [
    "## Questions 1. and 2.\n",
    "\n",
    "#### Link to Team Contract: https://docs.google.com/document/d/1uDSQLGPSfcgl3PisaC1-ngaViqJCkBiWFmDsN2FzZ9w/edit?usp=sharing\n",
    "#### Link ot Repo: https://github.com/UBC-MDS/DSCI_525_Group26"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e3c0afbb-bf67-4167-af62-aff939d0c994",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import glob\n",
    "import zipfile\n",
    "import requests\n",
    "from urllib.request import urlretrieve\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41c188a3-dd86-4253-9ca3-b3682c35144c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 3. Data Download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4360720a-7615-44bc-acfa-e366ab0594a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%cd /Users/apple/MDS/block6/525/DSCI_525_Group26/notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4fc1e342-abdc-4a16-bff1-f6cf1be59765",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Necessary metadata\n",
    "article_id = 14096681  # this is the unique identifier of the article on figshare\n",
    "url = f\"https://api.figshare.com/v2/articles/{article_id}\"\n",
    "headers = {\"Content-Type\": \"application/json\"}\n",
    "output_directory = \"figsharerainfall/\"\n",
    "\n",
    "# Query\n",
    "response = requests.request(\"GET\", url, headers=headers)\n",
    "data = json.loads(response.text)  # this contains all the articles data\n",
    "files = data[\"files\"]             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d005051c-b8a7-49b3-8776-d7f4d5f79013",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.19 s, sys: 6.97 s, total: 10.2 s\n",
      "Wall time: 2min 51s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "files_to_dl = [\"data.zip\"]  \n",
    "for file in files:\n",
    "    if file[\"name\"] in files_to_dl:\n",
    "        os.makedirs(output_directory, exist_ok=True)\n",
    "        urlretrieve(file[\"download_url\"], output_directory + file[\"name\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0f35fa0-83ce-41a6-af7b-acde0e236a21",
   "metadata": {
    "tags": []
   },
   "source": [
    "> Data Download Comparison\n",
    "\n",
    "| Team Member | Operating System | RAM | Processor | Is SSD | Time taken |\n",
    "|:-----------:|:----------------:|:---:|:---------:|:------:|:----------:|\n",
    "| Adam Morphy | MacOS Big Sur | 8GB | 1.8 GHz Dual-Core Intel Core i5 | Yes | 1m 6s|\n",
    "| Mukund Iyer | MacOS Monterey | 8GB | 1.4 GHz Quad-Core Intel Core i5 | Yes | 4min 18s |\n",
    "| Julien Gordon | Ubuntu 20.04.4 LTS | 16GB | AMD® Ryzen 7 5800h with radeon graphics | Yes | 2min 51s |\n",
    "| Shiva Shankar Jena | MacOS Catalina 10.15.7 | 4GB | 1.4 GHz Dual-Core Intel Core i5 | Yes | 1m 16s |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a1039289-a2fb-4d53-95fb-daff3c432d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting files from zip\n",
    "with zipfile.ZipFile(os.path.join(output_directory, \"data.zip\"), 'r') as f:\n",
    "    f.extractall(output_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffe91f57-5b49-4646-a74a-752a7c594565",
   "metadata": {},
   "source": [
    "## 4. Combining data CSVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b55889b6-e88c-4ff2-b8df-a7fb9e022fb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6min 35s, sys: 26.4 s, total: 7min 2s\n",
      "Wall time: 7min 23s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "#use_cols = [\"rain\", \"lat_min\", \"lat_max\", \"Ion_min\", \"Ion_max\", \"rain (mm/day)\", \"model\"]\n",
    "files = glob.glob('figsharerainfall/*.csv')\n",
    "excluded_files = [\"figsharerainfall/observed_daily_rainfall_SYD.csv\"]\n",
    "df = pd.concat(\n",
    "    (\n",
    "        pd.read_csv(file, index_col=0)\n",
    "        .assign(model=re.findall(r'\\/(.*?)_', file)[0])\n",
    "        for file in files\n",
    "        if file not in excluded_files\n",
    "        \n",
    "    )\n",
    ")\n",
    "df.to_csv(\"figsharerainfall/combined_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a44f1567-5984-4cbe-9661-e19304427a56",
   "metadata": {},
   "source": [
    "> Combining Data Comparison\n",
    "\n",
    "| Team Member | Operating System | RAM | Processor | Is SSD | Time taken |\n",
    "|:-----------:|:----------------:|:---:|:---------:|:------:|:----------:|\n",
    "| Adam Morphy | MacOS Big Sur | 8GB | 1.8 GHz Dual-Core Intel Core i5 | Yes | ~10m (DNF)|\n",
    "| Mukund Iyer | MacOS Monterey | 8GB | 1.4 GHz Quad-Core Intel Core i5 | Yes | 7min 23s |\n",
    "| Julien Gordon | Ubuntu 20.04.4 LTS | 16GB | AMD® Ryzen 7 5800h with radeon graphics | Yes | N/A (kernel chrash) |\n",
    "| Shiva Shankar Jena | MacOS Catalina 10.15.7 | 4GB | 1.4 GHz Dual-Core Intel Core i5 | Yes | 12m 58s |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0363bec5-fba1-4a1c-9262-4b686747a6e2",
   "metadata": {},
   "source": [
    "**Note:** Please note that Adam's machine was only able to run the analysis on a partially combined csv by stopping the combining process partway through completion. While this enabled him to finish the analysis, the timing results are misleading because the processes were not done on the full csv.\n",
    "\n",
    "Julien was unable to run the notebook as the kernel kept crashing. We suspect it may have to do with Apache Arrow not being optimised for his Ubuntu Linux distribution. Since his computer has 16gb of Ram, it is rather surprising that he was not able to run the notebook. However, the installation documentation lists Linux as supported (https://anaconda.org/conda-forge/arrow) so it is unclear why the issue is happening and this is mostly speculation.\n",
    "\n",
    "Overall, Mukund and Shiva's runtimes were consistent with what we would expect intuitively. Mukund's machine with double the working memory resulted in about half the time taken to complete the combining operation. This suggests a linear relationship between ram and time taken for this kind of task. It is useful for comparison that both of them have similar machines with the same processors. Interestingly, Adam's machine with a theoretically more powerful processor than Shiva's was unable to complete the task, but we were unable to determine the cause of this. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a0e2946-e346-42b1-8180-130b935c3468",
   "metadata": {},
   "source": [
    "## 5. Load the combined CSV to memory and perform a simple EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "278e05b6-562a-4b27-b9e5-f61b74e05f23",
   "metadata": {},
   "source": [
    "### 5.1 Investigating 2 approaches to reduce memory usage while performing the EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "809aef67-ea6a-42f8-a7de-2f65df261566",
   "metadata": {},
   "source": [
    "#### Loading the whole data and performing EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "032e86f8-5fa0-4b82-9952-cbe4c66d1a9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 5s, sys: 20.7 s, total: 1min 26s\n",
      "Wall time: 1min 32s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Loading data (Pandas)\n",
    "df_combined = pd.read_csv(\n",
    "    \"figsharerainfall/combined_data.csv\", \n",
    "    index_col=0,\n",
    "    parse_dates=True \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a463d19f-2146-45e7-8622-679b3caa7f0d",
   "metadata": {},
   "source": [
    "> Combining Data Comparison\n",
    "\n",
    "| Team Member | Operating System | RAM | Processor | Is SSD | Time taken |\n",
    "|:-----------:|:----------------:|:---:|:---------:|:------:|:----------:|\n",
    "| Adam Morphy | MacOS Big Sur | 8GB | 1.8 GHz Dual-Core Intel Core i5 | Yes | 1m 16s (limited data) |\n",
    "| Mukund Iyer | MacOS Monterey | 8GB | 1.4 GHz Quad-Core Intel Core i5 | Yes | 1min 32s |\n",
    "| Julien Gordon | Ubuntu 20.04.4 LTS | 16GB | AMD® Ryzen 7 5800h with radeon graphics | Yes | N/A (kernel crash) |\n",
    "| Shiva Shankar Jena | MacOS Catalina 10.15.7 | 4GB | 1.4 GHz Dual-Core Intel Core i5 | Yes | 3m 53s|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dfe8431-c9b6-4726-a18f-3739e7b87be8",
   "metadata": {},
   "source": [
    "Overall, once again Mukund and Shiva's runtimes were consistent with what we would expect intuitively. Mukund's machine with double the working memory resulted in about half the time taken to complete the data loading task. This suggests a linear relationship between ram and time taken for this kind of task. It is useful for comparison that both of them have similar machines with the same processors. Please note once again that working with a subset of the data, Adam's runtime is not a fair comparison across machines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ee146b0f-ffef-4f52-a915-df015188bd4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.33 s, sys: 116 ms, total: 3.44 s\n",
      "Wall time: 3.51 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MPI-ESM1-2-HR       5154240\n",
       "CMCC-CM2-HR4        3541230\n",
       "CMCC-ESM2           3541230\n",
       "CMCC-CM2-SR5        3541230\n",
       "NorESM2-MM          3541230\n",
       "TaiESM1             3541230\n",
       "SAM0-UNICON         3541153\n",
       "GFDL-ESM4           3219300\n",
       "FGOALS-f3-L         3219300\n",
       "GFDL-CM4            3219300\n",
       "MRI-ESM2-0          3037320\n",
       "EC-Earth3-Veg-LR    3037320\n",
       "BCC-CSM2-MR         3035340\n",
       "MIROC6              2070900\n",
       "ACCESS-CM2          1932840\n",
       "ACCESS-ESM1-5       1610700\n",
       "INM-CM4-8           1609650\n",
       "INM-CM5-0           1609650\n",
       "FGOALS-g3           1287720\n",
       "KIOST-ESM           1287720\n",
       "AWI-ESM-1-1-LR       966420\n",
       "MPI-ESM1-2-LR        966420\n",
       "NESM3                966420\n",
       "MPI-ESM-1-2-HAM      966420\n",
       "NorESM2-LM           919800\n",
       "BCC-ESM1             551880\n",
       "CanESM5              551880\n",
       "Name: model, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "df_combined.model.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c839222-62ce-4065-a18c-38812eb10697",
   "metadata": {},
   "source": [
    "> Performing a simple EDA\n",
    "\n",
    "| Team Member | Operating System | RAM | Processor | Is SSD | Time taken |\n",
    "|:-----------:|:----------------:|:---:|:---------:|:------:|:----------:|\n",
    "| Adam Morphy | MacOS Big Sur | 8GB | 1.8 GHz Dual-Core Intel Core i5 | Yes | 1.06s (limited data)  |\n",
    "| Mukund Iyer | MacOS Monterey | 8GB | 1.4 GHz Quad-Core Intel Core i5 | Yes | 3.51 s |\n",
    "| Julien Gordon | Ubuntu 20.04.4 LTS | 16GB | AMD® Ryzen 7 5800h with radeon graphics | Yes | N/A (kernel crash) |\n",
    "| Shiva Shankar Jena | MacOS Catalina 10.15.7 | 4GB | 1.4 GHz Dual-Core Intel Core i5 | Yes | 5.99s |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85df4176-5c3d-454f-b16b-5ecc34e076ca",
   "metadata": {},
   "source": [
    "Once more we observe that Mukund and Shiva's runtimes were consistent with previous findings. Mukund's machine with double the working memory resulted in about half the time taken to complete the EDA. This suggests a roughly linear relationship between ram and time taken for this kind of task. With this task being less onerous to complete, we see that the speed differential is not as pronounced as the previous exercises, which suggests that with smaller tasks, we do not observe as much benefits from more RAM as for larger tasks. Please note once again that working with a subset of the data, Adam's runtime is not a fair comparison across machines."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d217da25-a380-41b9-a215-738caa8f0254",
   "metadata": {},
   "source": [
    "### 5.1.1 Approach 1 to reduce memory usage: Changing dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "508e3bf4-2564-4365-b3b8-f3b9961af35a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lat_min          float64\n",
       "lat_max          float64\n",
       "lon_min          float64\n",
       "lon_max          float64\n",
       "rain (mm/day)    float64\n",
       "model             object\n",
       "dtype: object"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_combined.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5ff62450-4cdd-48e1-b2bb-1bd74dbbd52e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage with float64: 2998.46 MB\n",
      "Memory usage with float32: 1749.10 MB\n"
     ]
    }
   ],
   "source": [
    "print(f\"Memory usage with float64: {df_combined[['lat_min', 'lat_max','lon_min', 'lon_max', 'rain (mm/day)']].memory_usage().sum() / 1e6:.2f} MB\")\n",
    "print(f\"Memory usage with float32: {df_combined[['lat_min', 'lat_max','lon_min', 'lon_max', 'rain (mm/day)']].astype('float32', errors='ignore').memory_usage().sum() / 1e6:.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "21836f54-7e38-4b6e-ad1f-5eb5a9ccf62c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.67 s, sys: 3.85 s, total: 5.52 s\n",
      "Wall time: 7.71 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_combined_float32 = df_combined[['lat_min', 'lat_max','lon_min', 'lon_max', 'rain (mm/day)']].astype('float32', errors='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5217a249-8c23-4ab0-bf77-841c145a5bef",
   "metadata": {},
   "source": [
    "### 5.1.2 Approach 2 to reduce memory usage: loading in chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cd3a7bce-e539-48b5-8609-c306e132edec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACCESS-CM2          1932840\n",
      "ACCESS-ESM1-5       1610700\n",
      "AWI-ESM-1-1-LR       966420\n",
      "BCC-CSM2-MR         3035340\n",
      "BCC-ESM1             551880\n",
      "CMCC-CM2-HR4        3541230\n",
      "CMCC-CM2-SR5        3541230\n",
      "CMCC-ESM2           3541230\n",
      "CanESM5              551880\n",
      "EC-Earth3-Veg-LR    3037320\n",
      "FGOALS-f3-L         3219300\n",
      "FGOALS-g3           1287720\n",
      "GFDL-CM4            3219300\n",
      "GFDL-ESM4           3219300\n",
      "INM-CM4-8           1609650\n",
      "INM-CM5-0           1609650\n",
      "KIOST-ESM           1287720\n",
      "MIROC6              2070900\n",
      "MPI-ESM-1-2-HAM      966420\n",
      "MPI-ESM1-2-HR       5154240\n",
      "MPI-ESM1-2-LR        966420\n",
      "MRI-ESM2-0          3037320\n",
      "NESM3                966420\n",
      "NorESM2-LM           919800\n",
      "NorESM2-MM          3541230\n",
      "SAM0-UNICON         3541153\n",
      "TaiESM1             3541230\n",
      "dtype: int64\n",
      "CPU times: user 1min, sys: 8.12 s, total: 1min 8s\n",
      "Wall time: 1min 9s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Doing EDA with only chunks of data\n",
    "counts=pd.Series(dtype=int)\n",
    "for chunk in pd.read_csv(\n",
    "    \"figsharerainfall/combined_data.csv\",\n",
    "    parse_dates=True,\n",
    "    chunksize=1_000_000\n",
    "):\n",
    "    counts=counts.add(chunk.model.value_counts(), fill_value=0)\n",
    "\n",
    "print(counts.astype(int))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16ffd22d-6864-4fea-8c52-f69f81920829",
   "metadata": {},
   "source": [
    "> Loading data and performing a simple EDA with reduced memory usage (minimum out of 2 approaches)\n",
    "\n",
    "| Team Member | Operating System | RAM | Processor | Is SSD | Time taken |\n",
    "|:-----------:|:----------------:|:---:|:---------:|:------:|:----------:|\n",
    "| Adam Morphy | MacOS Big Sur | 8GB | 1.8 GHz Dual-Core Intel Core i5 | Yes | 27s (limited data)  |\n",
    "| Mukund Iyer | MacOS Monterey | 8GB | 1.4 GHz Quad-Core Intel Core i5 | Yes | 1min 9s |\n",
    "| Julien Gordon | Ubuntu 20.04.4 LTS | 16GB | AMD® Ryzen 7 5800h with radeon graphics | Yes | |\n",
    "| Shiva Shankar Jena | MacOS Catalina 10.15.7 | 4GB | 1.4 GHz Dual-Core Intel Core i5 | Yes | 1m 45s |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cb39240-b670-4f1e-abfa-0b827c9dc25e",
   "metadata": {},
   "source": [
    "We see that our chunking strategy did reduce time, but not by an overly significant margin. We can gather from this experience that these strategies in combination can perhaps make an impossible task for a machine possible, but there is a size of data for which these methods may not reduce the time required enough to be feasible. Once more the comparisons across machines are consistent with our previous observations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32edbc70-5ad3-4d1a-8730-83ef71663e89",
   "metadata": {},
   "source": [
    "## 6. Perform a simple EDA in R"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eedfcbc9-10f1-46f0-bba8-ecd28e20373c",
   "metadata": {},
   "source": [
    "### 6.1 Approaches to transfer the dataframe from python to R"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ab98506-2a3e-4803-9b69-42110c353d3d",
   "metadata": {},
   "source": [
    "We tried different approaches for data transfer to compare time taken."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36b4707d-d863-4340-89e4-430d830a7c73",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 6.1.1 Parquet file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d0140a7e-9a72-4af1-9634-59176d90903f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Using pandas\n",
    "\n",
    "df_combined.to_parquet(\"figsharerainfall/combined_data_partition.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b76a1fdd-707f-4fec-befb-137050782bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext rpy2.ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "946274a6-89e0-44a0-9952-e293f69c727d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rpy2_arrow.pyarrow_rarrow as pyra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "382350db-2889-43f8-a840-ef707bbed282",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "suppressMessages(library(arrow, warn.conflicts = FALSE))\n",
    "suppressMessages(library(dplyr, warn.conflicts = FALSE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4252d929-d1d5-474d-b29a-d9a0c0596a8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9.21 ms, sys: 13.2 ms, total: 22.4 ms\n",
      "Wall time: 32.8 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%R\n",
    "ds_rainfall <- open_dataset(\"figsharerainfall/combined_data_partition.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1efcfb96-a22a-4015-b6ee-c6b64949a322",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 27.7 ms, sys: 5.66 ms, total: 33.3 ms\n",
      "Wall time: 36.6 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%R\n",
    "query <- ds_rainfall %>%\n",
    "    select(model) %>%\n",
    "    group_by(model) %>%\n",
    "    summarise(\n",
    "        count = n()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e6e2600c-b6aa-455a-b3c6-162038b0b47c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# A tibble: 27 × 2\n",
      "   model              count\n",
      "   <chr>              <int>\n",
      " 1 MPI-ESM-1-2-HAM   966420\n",
      " 2 AWI-ESM-1-1-LR    966420\n",
      " 3 MRI-ESM2-0       3037320\n",
      " 4 GFDL-CM4         3219300\n",
      " 5 EC-Earth3-Veg-LR 3037320\n",
      " 6 INM-CM4-8        1609650\n",
      " 7 TaiESM1          3541230\n",
      " 8 CMCC-CM2-SR5     3541230\n",
      " 9 KIOST-ESM        1287720\n",
      "10 GFDL-ESM4        3219300\n",
      "# … with 17 more rows\n",
      "CPU times: user 3.95 s, sys: 803 ms, total: 4.75 s\n",
      "Wall time: 2.54 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%R\n",
    "print(query %>% collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "862b661d-ffad-466c-a52e-47da88c2a7dc",
   "metadata": {},
   "source": [
    "> Comparison of Loading data and EDA time in R using parquet file\n",
    "\n",
    "| Team Member | Operating System | RAM | Processor | Is SSD | Time taken | Method |\n",
    "|:-----------:|:----------------:|:---:|:---------:|:------:|:----------:|:----------:|\n",
    "| Adam Morphy | MacOS Big Sur | 8GB | 1.8 GHz Dual-Core Intel Core i5 | Yes | 1.74s (limited data) | Parquet file |\n",
    "| Mukund Iyer | MacOS Monterey | 8GB | 1.4 GHz Quad-Core Intel Core i5 | Yes | 2.54s | Parquet file |\n",
    "| Julien Gordon | Ubuntu 20.04.4 LTS | 16GB | AMD® Ryzen 7 5800h with radeon graphics | Yes | N/A (kernel crash) | N/A (kernel crash) |\n",
    "| Shiva Shankar Jena | MacOS Catalina 10.15.7 | 4GB | 1.4 GHz Dual-Core Intel Core i5 | Yes | 10s | Parquet file |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6b58651-353f-47d9-b887-8e52ac01e1e2",
   "metadata": {},
   "source": [
    "We see that the Parquet file resulted in a very low time requirement, but this may be partly because the task we were doing was not as arduous. Overall this shows the advantage of using Parquet files in reducing computation times. These advantages will be discussed below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e2711fb-a6e9-4b93-9be0-c28124cf4b96",
   "metadata": {},
   "source": [
    "### 6.2 Reasons for choosing the approaches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60b7033e-5125-4bbe-9c10-5fd4a306cfd6",
   "metadata": {},
   "source": [
    "1. Parquet file: The primary advantages of parquet file approach, apart from its hybrid file format for use in multiple languages, was that it lead to significantly reduced memory usage(539.6 MB compared to the 8 GB combined CSV file) as well as speed leveraging the power of efficient compression and encoding techniques of Arrow as well as the lazy evaluation benefits of R. The method proved immensely efficient. The implementation uses the same underlying C/C++ pointer for R and Python. The developers highlight a large gain in performance compared to typical ways of sharing arrays or data frames between Python and R through the conversion rules included in rpy2 (https://rpy2.github.io/rpy2-arrow/version/main/html/)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e19c9d35-7202-48be-a83c-66edb56473ec",
   "metadata": {},
   "source": [
    "### Overall Difficulties Discussion\n",
    "\n",
    "Overall we found that working with such large data presented unique difficulties that were hard to overcome. The time taken to complete basic components of the exercise introduced some frustration in terms of the lag between attempting a solution and finding out the outcome. Moreover, we found in Adam and Julien's case instances where we could not complete the exercise as intended. In Adam's case, reducing the amount of data loaded into working memory solved the problem. In Julien's case, the python kernel was crashing and we tried a different method's such as using reduced data size and making sure the environment was set up correctly. The issue is that with such opaque error messages, it is difficult to diagnose what the problem is and ultimately we used the other group member's machines for the analysis. Another simple difficulty we came across is that it is often useful to simply open a file to look at its data structure, column names, and other information. With such large datasets opening these is prohibitive, so we had to use other methods such as looking at a subset or programatically extracting the information we were looking for. We are looking forward to working on the cloud so as to reduce difficulties we experienced in this milestone."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:525_2022]",
   "language": "python",
   "name": "conda-env-525_2022-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
